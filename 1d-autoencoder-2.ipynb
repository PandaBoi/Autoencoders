{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from   torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "num_epochs = 1000\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc_1 = nn.Conv1d(in_channels=1, out_channels=1,kernel_size=16)\n",
    "        self.dec_1 = nn.ConvTranspose1d(in_channels=1,out_channels=1,kernel_size=16)\n",
    "        \n",
    "    def forward(self ,x):\n",
    "        x = self.enc_1(x)\n",
    "        x = self.dec_1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = torch.randn(10000,1,256)\n",
    "#no of signals = 10000\n",
    "#no of channels each = 1\n",
    "#length of each channel = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset class\n",
    "class SignalsDataset():\n",
    "    \n",
    "    def __init__(self, signals):\n",
    "        self.signals = signals\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.signals[idx], 'target': self.signals[idx]}\n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignalsDataset(signals)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:0.0603\n",
      "epoch [2/1000], loss:0.0534\n",
      "epoch [3/1000], loss:0.0550\n",
      "epoch [4/1000], loss:0.0580\n",
      "epoch [5/1000], loss:0.0476\n",
      "epoch [6/1000], loss:0.0538\n",
      "epoch [7/1000], loss:0.0550\n",
      "epoch [8/1000], loss:0.0567\n",
      "epoch [9/1000], loss:0.0504\n",
      "epoch [10/1000], loss:0.0725\n",
      "epoch [11/1000], loss:0.0693\n",
      "epoch [12/1000], loss:0.0581\n",
      "epoch [13/1000], loss:0.0600\n",
      "epoch [14/1000], loss:0.0598\n",
      "epoch [15/1000], loss:0.0657\n",
      "epoch [16/1000], loss:0.0665\n",
      "epoch [17/1000], loss:0.0601\n",
      "epoch [18/1000], loss:0.0504\n",
      "epoch [19/1000], loss:0.0429\n",
      "epoch [20/1000], loss:0.0707\n",
      "epoch [21/1000], loss:0.0691\n",
      "epoch [22/1000], loss:0.0581\n",
      "epoch [23/1000], loss:0.0591\n",
      "epoch [24/1000], loss:0.0702\n",
      "epoch [25/1000], loss:0.0512\n",
      "epoch [26/1000], loss:0.0633\n",
      "epoch [27/1000], loss:0.0510\n",
      "epoch [28/1000], loss:0.0501\n",
      "epoch [29/1000], loss:0.0647\n",
      "epoch [30/1000], loss:0.0578\n",
      "epoch [31/1000], loss:0.0628\n",
      "epoch [32/1000], loss:0.0591\n",
      "epoch [33/1000], loss:0.0640\n",
      "epoch [34/1000], loss:0.0728\n",
      "epoch [35/1000], loss:0.0604\n",
      "epoch [36/1000], loss:0.0490\n",
      "epoch [37/1000], loss:0.0591\n",
      "epoch [38/1000], loss:0.0577\n",
      "epoch [39/1000], loss:0.0501\n",
      "epoch [40/1000], loss:0.0586\n",
      "epoch [41/1000], loss:0.0554\n",
      "epoch [42/1000], loss:0.0584\n",
      "epoch [43/1000], loss:0.0574\n",
      "epoch [44/1000], loss:0.0645\n",
      "epoch [45/1000], loss:0.0666\n",
      "epoch [46/1000], loss:0.0620\n",
      "epoch [47/1000], loss:0.0603\n",
      "epoch [48/1000], loss:0.0585\n",
      "epoch [49/1000], loss:0.0527\n",
      "epoch [50/1000], loss:0.0466\n",
      "epoch [51/1000], loss:0.0657\n",
      "epoch [52/1000], loss:0.0587\n",
      "epoch [53/1000], loss:0.0595\n",
      "epoch [54/1000], loss:0.0501\n",
      "epoch [55/1000], loss:0.0584\n",
      "epoch [56/1000], loss:0.0630\n",
      "epoch [57/1000], loss:0.0652\n",
      "epoch [58/1000], loss:0.0580\n",
      "epoch [59/1000], loss:0.0590\n",
      "epoch [60/1000], loss:0.0482\n",
      "epoch [61/1000], loss:0.0546\n",
      "epoch [62/1000], loss:0.0559\n",
      "epoch [63/1000], loss:0.0533\n",
      "epoch [64/1000], loss:0.0630\n",
      "epoch [65/1000], loss:0.0541\n",
      "epoch [66/1000], loss:0.0573\n",
      "epoch [67/1000], loss:0.0562\n",
      "epoch [68/1000], loss:0.0669\n",
      "epoch [69/1000], loss:0.0664\n",
      "epoch [70/1000], loss:0.0486\n",
      "epoch [71/1000], loss:0.0589\n",
      "epoch [72/1000], loss:0.0547\n",
      "epoch [73/1000], loss:0.0618\n",
      "epoch [74/1000], loss:0.0586\n",
      "epoch [75/1000], loss:0.0597\n",
      "epoch [76/1000], loss:0.0550\n",
      "epoch [77/1000], loss:0.0593\n",
      "epoch [78/1000], loss:0.0579\n",
      "epoch [79/1000], loss:0.0528\n",
      "epoch [80/1000], loss:0.0666\n",
      "epoch [81/1000], loss:0.0633\n",
      "epoch [82/1000], loss:0.0565\n",
      "epoch [83/1000], loss:0.0536\n",
      "epoch [84/1000], loss:0.0596\n",
      "epoch [85/1000], loss:0.0450\n",
      "epoch [86/1000], loss:0.0530\n",
      "epoch [87/1000], loss:0.0471\n",
      "epoch [88/1000], loss:0.0612\n",
      "epoch [89/1000], loss:0.0540\n",
      "epoch [90/1000], loss:0.0520\n",
      "epoch [91/1000], loss:0.0554\n",
      "epoch [92/1000], loss:0.0650\n",
      "epoch [93/1000], loss:0.0658\n",
      "epoch [94/1000], loss:0.0702\n",
      "epoch [95/1000], loss:0.0591\n",
      "epoch [96/1000], loss:0.0603\n",
      "epoch [97/1000], loss:0.0617\n",
      "epoch [98/1000], loss:0.0657\n",
      "epoch [99/1000], loss:0.0543\n",
      "epoch [100/1000], loss:0.0607\n",
      "epoch [101/1000], loss:0.0506\n",
      "epoch [102/1000], loss:0.0568\n",
      "epoch [103/1000], loss:0.0613\n",
      "epoch [104/1000], loss:0.0582\n",
      "epoch [105/1000], loss:0.0588\n",
      "epoch [106/1000], loss:0.0563\n",
      "epoch [107/1000], loss:0.0540\n",
      "epoch [108/1000], loss:0.0757\n",
      "epoch [109/1000], loss:0.0500\n",
      "epoch [110/1000], loss:0.0489\n",
      "epoch [111/1000], loss:0.0506\n",
      "epoch [112/1000], loss:0.0504\n",
      "epoch [113/1000], loss:0.0575\n",
      "epoch [114/1000], loss:0.0515\n",
      "epoch [115/1000], loss:0.0566\n",
      "epoch [116/1000], loss:0.0588\n",
      "epoch [117/1000], loss:0.0705\n",
      "epoch [118/1000], loss:0.0705\n",
      "epoch [119/1000], loss:0.0550\n",
      "epoch [120/1000], loss:0.0509\n",
      "epoch [121/1000], loss:0.0550\n",
      "epoch [122/1000], loss:0.0622\n",
      "epoch [123/1000], loss:0.0479\n",
      "epoch [124/1000], loss:0.0532\n",
      "epoch [125/1000], loss:0.0582\n",
      "epoch [126/1000], loss:0.0701\n",
      "epoch [127/1000], loss:0.0664\n",
      "epoch [128/1000], loss:0.0552\n",
      "epoch [129/1000], loss:0.0485\n",
      "epoch [130/1000], loss:0.0711\n",
      "epoch [131/1000], loss:0.0656\n",
      "epoch [132/1000], loss:0.0590\n",
      "epoch [133/1000], loss:0.0550\n",
      "epoch [134/1000], loss:0.0489\n",
      "epoch [135/1000], loss:0.0613\n",
      "epoch [136/1000], loss:0.0615\n",
      "epoch [137/1000], loss:0.0662\n",
      "epoch [138/1000], loss:0.0697\n",
      "epoch [139/1000], loss:0.0568\n",
      "epoch [140/1000], loss:0.0575\n",
      "epoch [141/1000], loss:0.0579\n",
      "epoch [142/1000], loss:0.0608\n",
      "epoch [143/1000], loss:0.0571\n",
      "epoch [144/1000], loss:0.0460\n",
      "epoch [145/1000], loss:0.0473\n",
      "epoch [146/1000], loss:0.0629\n",
      "epoch [147/1000], loss:0.0607\n",
      "epoch [148/1000], loss:0.0615\n",
      "epoch [149/1000], loss:0.0556\n",
      "epoch [150/1000], loss:0.0743\n",
      "epoch [151/1000], loss:0.0509\n",
      "epoch [152/1000], loss:0.0492\n",
      "epoch [153/1000], loss:0.0651\n",
      "epoch [154/1000], loss:0.0648\n",
      "epoch [155/1000], loss:0.0619\n",
      "epoch [156/1000], loss:0.0589\n",
      "epoch [157/1000], loss:0.0528\n",
      "epoch [158/1000], loss:0.0474\n",
      "epoch [159/1000], loss:0.0681\n",
      "epoch [160/1000], loss:0.0668\n",
      "epoch [161/1000], loss:0.0591\n",
      "epoch [162/1000], loss:0.0619\n",
      "epoch [163/1000], loss:0.0483\n",
      "epoch [164/1000], loss:0.0616\n",
      "epoch [165/1000], loss:0.0518\n",
      "epoch [166/1000], loss:0.0585\n",
      "epoch [167/1000], loss:0.0662\n",
      "epoch [168/1000], loss:0.0487\n",
      "epoch [169/1000], loss:0.0612\n",
      "epoch [170/1000], loss:0.0470\n",
      "epoch [171/1000], loss:0.0636\n",
      "epoch [172/1000], loss:0.0555\n",
      "epoch [173/1000], loss:0.0578\n",
      "epoch [174/1000], loss:0.0566\n",
      "epoch [175/1000], loss:0.0598\n",
      "epoch [176/1000], loss:0.0528\n",
      "epoch [177/1000], loss:0.0452\n",
      "epoch [178/1000], loss:0.0728\n",
      "epoch [179/1000], loss:0.0621\n",
      "epoch [180/1000], loss:0.0631\n",
      "epoch [181/1000], loss:0.0592\n",
      "epoch [182/1000], loss:0.0547\n",
      "epoch [183/1000], loss:0.0639\n",
      "epoch [184/1000], loss:0.0501\n",
      "epoch [185/1000], loss:0.0578\n",
      "epoch [186/1000], loss:0.0444\n",
      "epoch [187/1000], loss:0.0590\n",
      "epoch [188/1000], loss:0.0628\n",
      "epoch [189/1000], loss:0.0601\n",
      "epoch [190/1000], loss:0.0503\n",
      "epoch [191/1000], loss:0.0429\n",
      "epoch [192/1000], loss:0.0521\n",
      "epoch [193/1000], loss:0.0645\n",
      "epoch [194/1000], loss:0.0535\n",
      "epoch [195/1000], loss:0.0606\n",
      "epoch [196/1000], loss:0.0587\n",
      "epoch [197/1000], loss:0.0678\n",
      "epoch [198/1000], loss:0.0602\n",
      "epoch [199/1000], loss:0.0634\n",
      "epoch [200/1000], loss:0.0577\n",
      "epoch [201/1000], loss:0.0692\n",
      "epoch [202/1000], loss:0.0706\n",
      "epoch [203/1000], loss:0.0632\n",
      "epoch [204/1000], loss:0.0569\n",
      "epoch [205/1000], loss:0.0591\n",
      "epoch [206/1000], loss:0.0497\n",
      "epoch [207/1000], loss:0.0468\n",
      "epoch [208/1000], loss:0.0510\n",
      "epoch [209/1000], loss:0.0705\n",
      "epoch [210/1000], loss:0.0549\n",
      "epoch [211/1000], loss:0.0698\n",
      "epoch [212/1000], loss:0.0704\n",
      "epoch [213/1000], loss:0.0555\n",
      "epoch [214/1000], loss:0.0564\n",
      "epoch [215/1000], loss:0.0566\n",
      "epoch [216/1000], loss:0.0560\n",
      "epoch [217/1000], loss:0.0566\n",
      "epoch [218/1000], loss:0.0496\n",
      "epoch [219/1000], loss:0.0540\n",
      "epoch [220/1000], loss:0.0716\n",
      "epoch [221/1000], loss:0.0556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-72132bdb2745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# ===================log========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Tensorplay-htnLUw2X/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Tensorplay-htnLUw2X/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i,sample in enumerate(dataloader):\n",
    "        data, target = sample['data'].to(device), sample['target'].to(device)\n",
    "        # ===================forward=====================\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # ===================backward====================\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
